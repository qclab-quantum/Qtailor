

env_version: 7

#rllib ppo start
###Iters is the number of batches the model will train on and the number of times your model weights will be updated (not counting minibatches).
stop_iters: 0

iters_arr:
  - 2

##One call to env.step() is one timestep.
stop_timesteps: 10000000

#the reward for multi-agent is the total sum (not the mean) over the agents.
stop_reward: 100
no_tune: False
local_mode: False
framework: torch
run: PPO
num_rollout_workers: 2
checkpoint_frequency: 10
checkpoint_at_end: True
rllib_lr: 1e-3
qasm: None
log_file_id: 0
as_test: False

#
#resume: False
checkpoint: None

#the save path of check_point zip file
check_point_zip_path: None


debug: False
#rllib ppo end